{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf9f8c-1e3e-46a3-9656-ecbd0f458c82",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [04:02<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall (mean score per model):\n",
      "                                                 model     score\n",
      "0                               gemini_gemini-2.5-pro  0.485430\n",
      "1                                               gpt-5  0.480139\n",
      "2                                          gpt-5-mini  0.452082\n",
      "3                     openrouter_perplexity_sonar-pro  0.442577\n",
      "4                             gemini_gemini-2.5-flash  0.410265\n",
      "5                              openrouter_x-ai_grok-4  0.360620\n",
      "6                        gemini_gemini-2.5-flash-lite  0.302948\n",
      "7                            Skywork_Skywork-R1V3-38B  0.277631\n",
      "8             openrouter_mistralai_mistral-medium-3.1  0.248612\n",
      "9                               google_gemma-3-27b-it  0.225179\n",
      "10                                         gpt-5-nano  0.212170\n",
      "11            openrouter_qwen_qwen2.5-vl-72b-instruct  0.205789\n",
      "12    openrouter_qwen_qwen2.5-vl-72b-instruct_oneline  0.202297\n",
      "13            openrouter_mistralai_pixtral-large-2411  0.200961\n",
      "14                              google_gemma-3-12b-it  0.187571\n",
      "15                                  AIDC-AI_Ovis2-34B  0.185032\n",
      "16                          OpenGVLab_InternVL3_5-38B  0.180017\n",
      "17                            OpenGVLab_InternVL3-38B  0.177584\n",
      "18                                  AIDC-AI_Ovis2-16B  0.171754\n",
      "19                            OpenGVLab_InternVL3-14B  0.161778\n",
      "20                          OpenGVLab_InternVL3_5-14B  0.160363\n",
      "21                        NCSOFT_VARCO-VISION-2.0-14B  0.155534\n",
      "22                               google_gemma-3-4b-it  0.154688\n",
      "23                                   AIDC-AI_Ovis2-8B  0.144342\n",
      "24  openrouter_mistralai_mistral-small-3.2-24b-ins...  0.144274\n",
      "25                           OpenGVLab_InternVL3_5-4B  0.140880\n",
      "26                             OpenGVLab_InternVL3-8B  0.137022\n",
      "27                           OpenGVLab_InternVL3_5-8B  0.131553\n",
      "28                        Qwen_Qwen2.5-VL-7B-Instruct  0.131544\n",
      "29  naver-hyperclovax_HyperCLOVAX-SEED-Vision-Inst...  0.126621\n",
      "30                                   AIDC-AI_Ovis2-4B  0.121776\n",
      "31                             OpenGVLab_InternVL3-9B  0.119991\n",
      "32                       NCSOFT_VARCO-VISION-2.0-1.7B  0.118689\n",
      "33                   openrouter_mistralai_pixtral-12b  0.111904\n",
      "34                                   AIDC-AI_Ovis2-2B  0.095352\n",
      "35                           OpenGVLab_InternVL3_5-2B  0.094751\n",
      "36                             OpenGVLab_InternVL3-2B  0.086989\n",
      "37                        Qwen_Qwen2.5-VL-3B-Instruct  0.081957\n",
      "38                                   AIDC-AI_Ovis2-1B  0.065177\n",
      "39                           OpenGVLab_InternVL3_5-1B  0.054311\n",
      "40                             OpenGVLab_InternVL3-1B  0.044506\n",
      "\n",
      "By Category (mean score per model & category):\n",
      "                       model     category     score\n",
      "0         AIDC-AI_Ovis2-16B       IT/컴퓨터  0.111963\n",
      "1         AIDC-AI_Ovis2-16B        건강/의료  0.389815\n",
      "2         AIDC-AI_Ovis2-16B           게임  0.080769\n",
      "3         AIDC-AI_Ovis2-16B        경제/경영  0.215841\n",
      "4         AIDC-AI_Ovis2-16B           과학  0.246811\n",
      "..                      ...          ...       ...\n",
      "528  openrouter_x-ai_grok-4           수학  0.220940\n",
      "529  openrouter_x-ai_grok-4    엔터테인먼트/예술  0.247667\n",
      "530  openrouter_x-ai_grok-4   자동차/자전거/교통  0.504254\n",
      "531  openrouter_x-ai_grok-4  자연물(동식물/곤충)  0.301842\n",
      "532  openrouter_x-ai_grok-4        코딩/개발  0.390185\n",
      "\n",
      "[533 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SCORES_DIR = Path(\"scores\")\n",
    "\n",
    "def parse_model_name(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Derive model name from filenames like:\n",
    "      litellm_MODEL_xxx.csv  or  vllm_MODEL_xxx.csv\n",
    "    Drops the 'litellm_'/'vllm_' prefix and the last underscore chunk (often a run id/timestamp).\n",
    "    \"\"\"\n",
    "    base = Path(filename).stem\n",
    "    for prefix in (\"litellm_\", \"vllm_\"):\n",
    "        if base.startswith(prefix):\n",
    "            base = base[len(prefix):]\n",
    "    parts = base.split(\"_\")\n",
    "    return \"_\".join(parts[:-1]) if len(parts) > 1 else base\n",
    "\n",
    "def get_score(s) -> float:\n",
    "    \"\"\"\n",
    "    Safely convert various 'score' representations to float.\n",
    "    Accepts numbers, numeric strings, or dict-like strings with 'value' (e.g., \"{'value': 0.83}\").\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return 0.0\n",
    "    if isinstance(s, (int, float, np.number)):\n",
    "        return float(s)\n",
    "    s = str(s).strip()\n",
    "    # Try dict-like with 'value'\n",
    "    try:\n",
    "        d = ast.literal_eval(s)\n",
    "        if isinstance(d, dict) and \"value\" in d:\n",
    "            return float(d[\"value\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: try to parse as plain float\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# Aggregators\n",
    "overall = defaultdict(lambda: {\"sum\": 0.0, \"cnt\": 0})\n",
    "by_cat = defaultdict(lambda: defaultdict(lambda: {\"sum\": 0.0, \"cnt\": 0}))\n",
    "\n",
    "for fp in tqdm(os.listdir(SCORES_DIR)):\n",
    "    if not fp.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(SCORES_DIR / fp)\n",
    "    if \"score\" not in df.columns or \"category\" not in df.columns:\n",
    "        # Skip files that don't have the needed columns\n",
    "        continue\n",
    "\n",
    "    df[\"score_num\"] = df[\"score\"].apply(get_score)\n",
    "    model = parse_model_name(fp)\n",
    "\n",
    "    # Overall aggregation\n",
    "    overall[model][\"sum\"] += df[\"score_num\"].sum()\n",
    "    overall[model][\"cnt\"] += df[\"score_num\"].shape[0]\n",
    "\n",
    "    # Per-category aggregation\n",
    "    for cat, grp in df.groupby(\"category\", dropna=False):\n",
    "        by_cat[model][cat][\"sum\"] += grp[\"score_num\"].sum()\n",
    "        by_cat[model][cat][\"cnt\"] += grp[\"score_num\"].shape[0]\n",
    "\n",
    "# Finalize means\n",
    "model_overall = {\n",
    "    m: (v[\"sum\"] / v[\"cnt\"]) if v[\"cnt\"] else 0.0\n",
    "    for m, v in overall.items()\n",
    "}\n",
    "model_by_category = {\n",
    "    m: {c: (vc[\"sum\"] / vc[\"cnt\"]) if vc[\"cnt\"] else 0.0 for c, vc in cats.items()}\n",
    "    for m, cats in by_cat.items()\n",
    "}\n",
    "\n",
    "# (Optional) Pretty DataFrames\n",
    "overall_df = (\n",
    "    pd.DataFrame([{\"model\": m, \"score\": s} for m, s in model_overall.items()])\n",
    "      .sort_values(\"score\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bycat_rows = []\n",
    "for m, cats in model_by_category.items():\n",
    "    for c, s in cats.items():\n",
    "        bycat_rows.append({\"model\": m, \"category\": c, \"score\": s})\n",
    "bycat_df = (\n",
    "    pd.DataFrame(bycat_rows)\n",
    "      .sort_values([\"model\", \"category\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Overall (mean score per model):\\n\", overall_df)\n",
    "print(\"\\nBy Category (mean score per model & category):\\n\", bycat_df)\n",
    "\n",
    "# Wide table: model (rows) × category (columns)\n",
    "wide_df = (\n",
    "    bycat_df.pivot_table(index=\"model\", columns=\"category\", values=\"score\", aggfunc=\"mean\")\n",
    "            .sort_index()\n",
    "            .sort_index(axis=1)\n",
    ")\n",
    "\n",
    "# (Optional) add overall mean as the leftmost column\n",
    "overall_s = overall_df.set_index(\"model\")[\"score\"]\n",
    "wide_df = overall_s.to_frame(\"Overall\").join(wide_df)\n",
    "\n",
    "# (Optional) tidy up\n",
    "wide_df = wide_df.round(4).fillna(0.0)\n",
    "\n",
    "wide_df.to_excel(\"scores_summary_by_category_gemini25flash.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cefa33d-a95e-41ae-877e-a15db86a8b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1a4ba8-4a97-4c57-8092-4407616362af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('scores_gemini/vllm_Qwen_Qwen2.5-VL-3B-Instruct_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485882b6-161e-405b-9657-dc7046ac1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [04:00<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall (mean/std per model):\n",
      "                                                 model      mean       std  \\\n",
      "0                               gemini_gemini-2.5-pro  0.485430  0.361108   \n",
      "1                                               gpt-5  0.480139  0.376761   \n",
      "2                                          gpt-5-mini  0.452082  0.351147   \n",
      "3                     openrouter_perplexity_sonar-pro  0.442577  0.339074   \n",
      "4                             gemini_gemini-2.5-flash  0.410265  0.352886   \n",
      "5                              openrouter_x-ai_grok-4  0.360620  0.350348   \n",
      "6                        gemini_gemini-2.5-flash-lite  0.302948  0.306091   \n",
      "7                            Skywork_Skywork-R1V3-38B  0.277631  0.287605   \n",
      "8             openrouter_mistralai_mistral-medium-3.1  0.248612  0.283986   \n",
      "9                               google_gemma-3-27b-it  0.225179  0.271094   \n",
      "10                                         gpt-5-nano  0.212170  0.299328   \n",
      "11            openrouter_qwen_qwen2.5-vl-72b-instruct  0.205789  0.248106   \n",
      "12    openrouter_qwen_qwen2.5-vl-72b-instruct_oneline  0.202297  0.250629   \n",
      "13            openrouter_mistralai_pixtral-large-2411  0.200961  0.255800   \n",
      "14                              google_gemma-3-12b-it  0.187571  0.250780   \n",
      "15                                  AIDC-AI_Ovis2-34B  0.185032  0.237022   \n",
      "16                          OpenGVLab_InternVL3_5-38B  0.180017  0.232764   \n",
      "17                            OpenGVLab_InternVL3-38B  0.177584  0.233048   \n",
      "18                                  AIDC-AI_Ovis2-16B  0.171754  0.233420   \n",
      "19                            OpenGVLab_InternVL3-14B  0.161778  0.228537   \n",
      "20                          OpenGVLab_InternVL3_5-14B  0.160363  0.222277   \n",
      "21                        NCSOFT_VARCO-VISION-2.0-14B  0.155534  0.216854   \n",
      "22                               google_gemma-3-4b-it  0.154688  0.226144   \n",
      "23                                   AIDC-AI_Ovis2-8B  0.144342  0.208937   \n",
      "24  openrouter_mistralai_mistral-small-3.2-24b-ins...  0.144274  0.218106   \n",
      "25                           OpenGVLab_InternVL3_5-4B  0.140880  0.210009   \n",
      "26                             OpenGVLab_InternVL3-8B  0.137022  0.204242   \n",
      "27                           OpenGVLab_InternVL3_5-8B  0.131553  0.205009   \n",
      "28                        Qwen_Qwen2.5-VL-7B-Instruct  0.131544  0.199077   \n",
      "29  naver-hyperclovax_HyperCLOVAX-SEED-Vision-Inst...  0.126621  0.198082   \n",
      "30                                   AIDC-AI_Ovis2-4B  0.121776  0.188411   \n",
      "31                             OpenGVLab_InternVL3-9B  0.119991  0.193160   \n",
      "32                       NCSOFT_VARCO-VISION-2.0-1.7B  0.118689  0.187215   \n",
      "33                   openrouter_mistralai_pixtral-12b  0.111904  0.195764   \n",
      "34                                   AIDC-AI_Ovis2-2B  0.095352  0.169862   \n",
      "35                           OpenGVLab_InternVL3_5-2B  0.094751  0.168880   \n",
      "36                             OpenGVLab_InternVL3-2B  0.086989  0.163557   \n",
      "37                        Qwen_Qwen2.5-VL-3B-Instruct  0.081957  0.158808   \n",
      "38                                   AIDC-AI_Ovis2-1B  0.065177  0.140863   \n",
      "39                           OpenGVLab_InternVL3_5-1B  0.054311  0.133159   \n",
      "40                             OpenGVLab_InternVL3-1B  0.044506  0.116385   \n",
      "\n",
      "       n  \n",
      "0   1959  \n",
      "1   1959  \n",
      "2   1959  \n",
      "3   1959  \n",
      "4   1959  \n",
      "5   1959  \n",
      "6   1959  \n",
      "7   1959  \n",
      "8   1959  \n",
      "9   1959  \n",
      "10  1959  \n",
      "11  1959  \n",
      "12   653  \n",
      "13  1959  \n",
      "14  1959  \n",
      "15  1959  \n",
      "16  1959  \n",
      "17  1959  \n",
      "18  1959  \n",
      "19  1959  \n",
      "20  1959  \n",
      "21  1959  \n",
      "22  1959  \n",
      "23  1959  \n",
      "24  1959  \n",
      "25  1959  \n",
      "26  1959  \n",
      "27  1959  \n",
      "28  1959  \n",
      "29  1959  \n",
      "30  1959  \n",
      "31  1959  \n",
      "32  1959  \n",
      "33  1959  \n",
      "34  1959  \n",
      "35  1959  \n",
      "36  1959  \n",
      "37  1959  \n",
      "38  1959  \n",
      "39  1959  \n",
      "40  1959  \n",
      "\n",
      "By Category (mean/std per model & category):\n",
      "                       model     category      mean       std    n\n",
      "0         AIDC-AI_Ovis2-16B       IT/컴퓨터  0.111963  0.226079  225\n",
      "1         AIDC-AI_Ovis2-16B        건강/의료  0.389815  0.307003   63\n",
      "2         AIDC-AI_Ovis2-16B           게임  0.080769  0.172247  273\n",
      "3         AIDC-AI_Ovis2-16B        경제/경영  0.215841  0.279633  111\n",
      "4         AIDC-AI_Ovis2-16B           과학  0.246811  0.216003  243\n",
      "..                      ...          ...       ...       ...  ...\n",
      "528  openrouter_x-ai_grok-4           수학  0.220940  0.343029   78\n",
      "529  openrouter_x-ai_grok-4    엔터테인먼트/예술  0.247667  0.310680  150\n",
      "530  openrouter_x-ai_grok-4   자동차/자전거/교통  0.504254  0.341607  105\n",
      "531  openrouter_x-ai_grok-4  자연물(동식물/곤충)  0.301842  0.295427  276\n",
      "532  openrouter_x-ai_grok-4        코딩/개발  0.390185  0.392210  135\n",
      "\n",
      "[533 rows x 5 columns]\n",
      "\n",
      "Saved summary to: scores_summary_by_category_gemini25flash.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SCORES_DIR = Path(\"scores\")\n",
    "\n",
    "def parse_model_name(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Derive model name from filenames like:\n",
    "      litellm_MODEL_xxx.csv  or  vllm_MODEL_xxx.csv\n",
    "    Drops the 'litellm_'/'vllm_' prefix and the last underscore chunk (often a run id/timestamp).\n",
    "    \"\"\"\n",
    "    base = Path(filename).stem\n",
    "    for prefix in (\"litellm_\", \"vllm_\"):\n",
    "        if base.startswith(prefix):\n",
    "            base = base[len(prefix):]\n",
    "    parts = base.split(\"_\")\n",
    "    return \"_\".join(parts[:-1]) if len(parts) > 1 else base\n",
    "\n",
    "def get_score(s) -> float:\n",
    "    \"\"\"\n",
    "    Safely convert various 'score' representations to float.\n",
    "    Accepts numbers, numeric strings, or dict-like strings with 'value' (e.g., \"{'value': 0.83}\").\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return 0.0\n",
    "    if isinstance(s, (int, float, np.number)):\n",
    "        return float(s)\n",
    "    s = str(s).strip()\n",
    "    # Try dict-like with 'value'\n",
    "    try:\n",
    "        d = ast.literal_eval(s)\n",
    "        if isinstance(d, dict) and \"value\" in d:\n",
    "            return float(d[\"value\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: try to parse as plain float\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "class RunningStats:\n",
    "    \"\"\"Welford's online algorithm for mean/std (sample std, ddof=1).\"\"\"\n",
    "    __slots__ = (\"n\", \"mean\", \"M2\")\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.mean = 0.0\n",
    "        self.M2 = 0.0\n",
    "    def update(self, x: float):\n",
    "        self.n += 1\n",
    "        delta = x - self.mean\n",
    "        self.mean += delta / self.n\n",
    "        delta2 = x - self.mean\n",
    "        self.M2 += delta * delta2\n",
    "    @property\n",
    "    def count(self) -> int:\n",
    "        return self.n\n",
    "    @property\n",
    "    def var(self) -> float:\n",
    "        if self.n > 1:\n",
    "            return self.M2 / (self.n - 1)\n",
    "        return np.nan\n",
    "    @property\n",
    "    def std(self) -> float:\n",
    "        v = self.var\n",
    "        return float(np.sqrt(v)) if not np.isnan(v) else np.nan\n",
    "\n",
    "# Aggregators: model-level and model→category-level\n",
    "overall = defaultdict(RunningStats)\n",
    "by_cat = defaultdict(lambda: defaultdict(RunningStats))\n",
    "\n",
    "for fp in tqdm(os.listdir(SCORES_DIR)):\n",
    "    if not fp.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(SCORES_DIR / fp)\n",
    "    if \"score\" not in df.columns or \"category\" not in df.columns:\n",
    "        # Skip files that don't have the needed columns\n",
    "        continue\n",
    "\n",
    "    df[\"score_num\"] = df[\"score\"].apply(get_score)\n",
    "    model = parse_model_name(fp)\n",
    "\n",
    "    # Update overall stats\n",
    "    for x in df[\"score_num\"].values:\n",
    "        overall[model].update(float(x))\n",
    "\n",
    "    # Update per-category stats\n",
    "    for cat, grp in df.groupby(\"category\", dropna=False):\n",
    "        rs = by_cat[model][cat]\n",
    "        for x in grp[\"score_num\"].values:\n",
    "            rs.update(float(x))\n",
    "\n",
    "# Build tidy DataFrames\n",
    "overall_rows = []\n",
    "for m, rs in overall.items():\n",
    "    overall_rows.append({\n",
    "        \"model\": m,\n",
    "        \"mean\": rs.mean,\n",
    "        \"std\": rs.std,\n",
    "        \"n\": rs.count,\n",
    "    })\n",
    "overall_df = (\n",
    "    pd.DataFrame(overall_rows)\n",
    "      .sort_values(\"mean\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "bycat_rows = []\n",
    "for m, cats in by_cat.items():\n",
    "    for c, rs in cats.items():\n",
    "        bycat_rows.append({\n",
    "            \"model\": m,\n",
    "            \"category\": c,\n",
    "            \"mean\": rs.mean,\n",
    "            \"std\": rs.std,\n",
    "            \"n\": rs.count,\n",
    "        })\n",
    "bycat_df = (\n",
    "    pd.DataFrame(bycat_rows)\n",
    "      .sort_values([\"model\", \"category\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Overall (mean/std per model):\\n\", overall_df)\n",
    "print(\"\\nBy Category (mean/std per model & category):\\n\", bycat_df)\n",
    "\n",
    "# Wide table with MultiIndex columns: (Category, Metric) where Metric ∈ {mean, std}\n",
    "pivot = bycat_df.pivot_table(\n",
    "    index=\"model\",\n",
    "    columns=\"category\",\n",
    "    values=[\"mean\", \"std\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "# Make columns as (Category, Metric) instead of (Metric, Category)\n",
    "pivot = pivot.swaplevel(0, 1, axis=1).sort_index(axis=1, level=0)\n",
    "\n",
    "# Add Overall group on the left\n",
    "overall_pair = overall_df.set_index(\"model\")[[\"mean\", \"std\"]]\n",
    "overall_pair.columns = pd.MultiIndex.from_product([[\"Overall\"], overall_pair.columns])\n",
    "\n",
    "wide_df = pd.concat([overall_pair, pivot], axis=1)\n",
    "\n",
    "# Tidy up\n",
    "wide_df = wide_df.round(4)\n",
    "\n",
    "# Write to Excel\n",
    "out_path = \"scores_summary_by_category_gemini25flash.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"xlsxwriter\") as writer:\n",
    "    overall_df.round(4).to_excel(writer, sheet_name=\"overall_mean_std\", index=False)\n",
    "    bycat_df.round(4).to_excel(writer, sheet_name=\"by_category_mean_std\", index=False)\n",
    "    wide_df.to_excel(writer, sheet_name=\"wide_mean_std\")\n",
    "\n",
    "print(f\"\\nSaved summary to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bdf16f-6d67-4485-8624-7dfc24c07f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xlsxwriter\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe6aca-b2eb-4e85-b369-86052a767f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
